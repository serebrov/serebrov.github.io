<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Amazon DynamoDB, EMR and Hive notes</title>

    <!-- Bootstrap -->
    <!-- https://github.com/necolas/normalize.css -->
    <link href="/css/normalize.css" rel="stylesheet">
    <!-- https://github.com/oxalorg/sakura -->
    <link href="/css/sakura.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/custom.css"/>

    <!-- https://prismjs.com/ -->
    <!-- Plugins: Line Highlight, Line Numbers, Autolinker, File Highlight,
                  Keep Markup, Normalize Whitespace
    -->
    <!-- Langs: bash, c, cpp, docker, go, haskell, json, makefile, php, plsql,
                python, rust, smalltalk, sql, vim, yaml
    -->
    <link href="/css/prism.css" rel="stylesheet">
    <script src="/js/prism.js"></script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
  </head>
  <body>
    <div class="content">
      <div class="page-header">
        <a href="/">vim, git, aws and other three-letter words</a>
      </div>
      <div class="post-title">
          <h1>Amazon DynamoDB, EMR and Hive notes</h1>
      </div>
      <div class="post-body">
          <p>First you need the EMR cluster running and you should have ssh connection to the master instance like described in the <a href="http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-get-started.html">getting started tutorial</a>.</p>
<p>Now it is possible to run Hive commands in few following ways:</p>
<ul>
<li>Connect via ssh, launch hive and run commands interactively</li>
<li>Create a script file with commands, upload it to S3 and launch as a ERM &#39;Hive program&#39; <a href="http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/CLI_CreatingaJobFlowUsingHive.html">step</a></li>
<li>Run it from Hue web-interface (see below)</li>
</ul>
<!-- more -->

<h3 id="connect-to-hue">Connect to Hue</h3>
<p>Hue is a Hadoop <a href="http://gethue.com/">web interface</a>. It is automatically installed when EMR cluster is launched.
The recommended way to connect to Hue is via <a href="http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/gsg-hue.html">ssh tunnel</a>, <a href="http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/accessing-hue.html">see also</a>.</p>
<p>But there is a simpler way (but less secure) - open the 8888 port on the master EMR instance:</p>
<ul>
<li>open security groups in EC2 console, find ElasticMapReduce-master and add</li>
<li>Custom TCP Rule, Port 8888, Anywhere</li>
<li>Check EMR master public DNS</li>
<li>Open Hue: <a href="http://ec2-XX-XXX-XX-XXX.region-name.compute.amazonaws.com:8888/">http://ec2-XX-XXX-XX-XXX.region-name.compute.amazonaws.com:8888/</a></li>
</ul>
<h3 id="analyze-dynamodb-data-with-hive">Analyze DynamoDB data with Hive</h3>
<p>To analyze the DynamoDB data there are following options:</p>
<ul>
<li>Create the external Hive table pointing to DynamoDB table and make queries against it (slow and consumes DynamoDB resources)</li>
<li>Export data from dynamo to the native Hive table then query this data off-line</li>
<li>Export data from dynamo to S3 and then query it, in this case queries are a bit slower than for a native Hive table, but data persists on S3, so it is possible to terminate the cluster and then launch it again when necessary</li>
</ul>
<p>Example of the script to move data from dynamo to hive native table:</p>
<pre><code class="lang-sql">-- Here you can drop/create an external table at any time - this will not affect real data
CREATE EXTERNAL TABLE dynamo_table (hash string, range bigint, data string)
STORED BY &#39;org.apache.hadoop.hive.dynamodb.DynamoDBStorageHandler&#39;
TBLPROPERTIES (&quot;dynamodb.table.name&quot; = &quot;mytable&quot;,
&quot;dynamodb.column.mapping&quot; = &quot;hash:hash,range:range,data:data&quot;);

CREATE TABLE hive_table (hash string, range bigint, data string);

SET dynamodb.throughput.read.percent=0.9;

INSERT OVERWRITE TABLE hive_table SELECT * FROM dynamo_table;
</code></pre>
<p>Example of the script to move data from dynamo to S3:</p>
<pre><code class="lang-sql">CREATE EXTERNAL TABLE dynamo_table (hash string, range bigint, data string)
STORED BY &#39;org.apache.hadoop.hive.dynamodb.DynamoDBStorageHandler&#39;
TBLPROPERTIES (&quot;dynamodb.table.name&quot; = &quot;mytable&quot;,
&quot;dynamodb.column.mapping&quot; = &quot;hash:hash,range:range,data:data&quot;);

CREATE EXTERNAL TABLE s3_table(hash string, range bigint, data string)
ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;,&#39;
LOCATION &#39;s3://my-bucket-name/2015-01-24-dynamo-table-data/&#39;;

INSERT OVERWRITE TABLE s3_table SELECT * FROM dynamo_table;
</code></pre>
<h3 id="hive-timestamp-to-date-conversions">Hive - timestamp to date conversions</h3>
<p>Examples of some queries to convert the timestamp to date string:</p>
<pre><code class="lang-sql">-- Convert timestamp to date in UTC+2 timezone
select hash, stamp, from_unixtime(stamp, &#39;y-M-d H:m:sZ+0200&#39;) from hive_table limit 10;

-- Select data by date string
select hash, stamp from hive_table where stamp &gt; unix_timestamp(&#39;2014-12-25 10:18:41+0200&#39;) limit 10;
</code></pre>
<h3 id="execute-python-script-from-hive-script">Execute python script from Hive script</h3>
<p>It is possible to transform data in Hive using external python script (see <a href="http://andreyfradkin.com/posts/2013/06/15/combining-hive-and-python/">here</a> and <a href="http://www.lichun.cc/blog/2012/06/wordcount-mapreduce-example-using-hive-on-local-and-emr/">here</a>).
And using a fake table it is possible to run the python script from the hive script:</p>
<pre><code class="lang-sql">--
-- Run python script to create test tables on dynamo.
-- Script should be uploaded to tapway-scripts/ on s3
--
CREATE TABLE IF NOT EXISTS empty_src (id string);
add file s3://tapway-scripts/hive.copy.test.py;
select transform (id) using &#39;hive.copy.test.py&#39; from empty_src;
</code></pre>
<h2 id="links">Links</h2>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual">Hive Language Manual</a></p>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF">Hive Operators and User-Defined Functions</a></p>
<p><a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/EMR_Hive_Commands.html">DynamoDB Guide: Hive Command Examples for Exporting, Importing, and Querying Data in DynamoDB</a></p>
<p><a href="http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/EMRforDynamoDB.html">EMR Guide: Export, Import, Query, and Join Tables in DynamoDB Using Amazon EMR</a></p>
<p><a href="http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/EMR_Hive_Optimizing.html">Optimizing Performance for Amazon EMR Operations in DynamoDB</a></p>
<p><a href="https://aws.amazon.com/articles/Elastic-MapReduce/28549">Using DynamoDB with Amazon Elastic MapReduce</a></p>
<p><a href="http://arjon.es/2014/01/29/hive-dynamodb-pitfalls/">Hive &amp; DynamoDB Pitfalls</a></p>
<p><a href="http://stackoverflow.com/questions/10683136/amazon-elastic-mapreduce-mass-insert-from-s3-to-dynamodb-is-incredibly-slow">Stackoverflow: Amazon Elastic MapReduce - mass insert from S3 to DynamoDB is incredibly slow</a></p>
<p><a href="http://martinharrigan.blogspot.com/2013/07/amazon-dynamodb-apache-hive-and-leaky.html">Amazon DynamoDB, Apache Hive and Leaky Abstractions</a></p>
<p><a href="http://blog.singhanuvrat.com/tech/amazon-aws-hive-emr-and-dynamodb">Amazon AWS: Hive, EMR and DynamoDb</a></p>
<p><a href="https://ariyabala.wordpress.com/2013/09/13/exploring-dynamo-db/">Exploring Dynamo DB</a></p>

      </div>
      <div>
<a href="https://stackexchange.com/users/261528">
<img src="https://stackexchange.com/users/flair/261528.png?theme=clean" width="208" height="58" alt="profile for Boris Serebrov on Stack Exchange, a network of free, community-driven Q&amp;A sites" title="profile for Boris Serebrov on Stack Exchange, a network of free, community-driven Q&amp;A sites">
</a>
      </div>
      <div>
<div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'serebrov'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
      </div>
    </div>

    <script src="https://ajax.googleapis.com/ajax/libs/angularjs/1.3.15/angular.min.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-58056088-1', 'auto');
  ga('send', 'pageview');

</script>
  </body>
</html>

